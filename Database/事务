参考链接：https://tech.ipalfish.com/blog/2020/03/26/isolation/

参考书籍：《数据密集型应用系统设计》

# 事务



## 事务源于何时

​	目前所有的关系型和一些非关系型数据库，都支持事务处理，大多都沿用1975年IBM推出的第一个SQL数据SystemR的总体设计。



## 为什么要用事务进行数据处理

​	数据处理往往会出现并发问题，脏读、脏写、写倾斜、幻读等，而处理这些问题要求存储引擎对数据的更改要保证强隔离的ACID性质。



## 事务的安全保证

### ACID

- 原子性
  - 一次事务的操作不可分割，要么提交成功，要么提交失败
  - 其他线程只能看到该操作的原来的值、更新后的值，过程中修改的值是看不到的
- 一致性
  - 更新操作不会导致原有关系（约束）的变动
- 隔离性
  - 多线程之间数据操作互不干扰
- 持久性
  - 数据持久化到磁盘后不会丢失



### BASE

- Basically Availiable 基本可用
- Soft State 软状态
- Eventual consistency 最终一致性





## 事务的隔离级别

### 追求高性能的隔离界别： 读 - 未提交

- 无法防止多线程数据操作带来的数据不一致问题。





### 默认隔离级别：读 - 提交

- 写：数据增加写锁，其他事务的写操作需要在该事务之后提交，解决了数据脏写问题
- 读： 当前数据具有两个版本，一个是对其他事务可见的旧的已提交的版本，一个是当前事务可见未提交的版本。解决数据脏读问题
- **【更新丢失】**对于 读 - 修改 - 写回的事务，会出现数据更新问题，比如A和B同时读取K值，并在各自的版本中对数据进行修改操作，最终的存储结果并不是A+B，而是A Or B；
  - **【显示加锁】**可以通过对读操作显示加锁，但会影响其他自读的事务。
  - **尽量用Update语句替换或不使用读-修改-写回的事务**
  - 一种更好的避免更新丢失的方式是数据库提供自动检测更新丢失的机制。目前PostgreSQL和TiDB的可重复读，Oracle的可串行化等都提供自动检测更新丢失的机制，**但是mysql的InnoDB的可重复读并不支持。**
  - 在不为可重复读下，还可以通过原子比较和设置来实现，例如：update table set value＝newvalue where id＝＊ and value＝oldvalue。
- **【不可重复读问题】**单次事务多次读取过程中，会因其他事务的提交导致数据不一致
- **【写倾斜问题】**当两个事务同时以某个条件查询数据，并在提交时更改了数据导致先前的查询条件失效。写倾斜可以通过显示加锁，进行可串行化处理或采用可串行化的快照隔离、串行化方案。



## 可重复读

​	*引入MVCC机制，每个事务在启动时自动获取一个自增且唯一的事务ID，单个事务多次读取，只能读取自己的快照版本。*【**解决不可重复读问题**】

​	*数据删除采用墓碑标记删除机制，只有当没有其他事务关联墓碑标记的数据时，存储引擎才会将数据删除。*

- 依然有**写倾斜**问题。
- 目前PostgreSQL和TiDB的可重复读，Oracle的可串行化等都提供自动检测更新丢失的机制，**但是mysql的InnoDB的可重复读并不支持，所以还是有【更新丢失问题】，需要手动加上间隙锁**





## 可串行的快照隔离

​	基于SSI（Serializeable SnapShot Isolation）算法，进行在事务提交时，如果检测到事务ID比当前ID大，则中止事务进行重试【**解决更新丢失问题**】，但如果多个事务对同一个对象进行操作时，当数据库性能达到瓶颈，重试事务会让系统雪上加霜。

**【解决写倾斜问题】** SSI锁，与间隙锁相似，但他允许锁住的区间进行更改，当事务提交时，检查当前事务是否对查询条件内容进行更改以及数据的事务ID是否被其他事务修改，从而解决写倾斜问题。

- 数据库：PostgreSQL（>9.1）、FoundationDB。



## 串行化

​	串行化一直是最不理想的数据隔离级别，其在多线程大量写事务的表现极其恶劣。但当今串行化的产品却受人欢迎，如VoltDB、H-Store、Redis、Datomic。原因大致如下：

1. 随着内存价格不断下降，数据从磁盘搬到内存成为可能，减少了读写数据的IO操作（备份还是要走磁盘滴）
2. 研究表明，OLTP事务通常执行很快，只有少部分读写操作，对于时间较长的OLAP数据库可以走快照隔离的方案



串行化方式实现：

1. 采用存储过程封装事务（Redis Lua），（但不能完全保证原子性）
2. 单个CPU核保证数据串行执行
3. 当写入操作较多时可以考虑数据分区。